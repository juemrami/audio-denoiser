{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = K.mean(K.square(K.abs(y_true-y_pred)))\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "model_path = os.path.join('saved/models', 'lstm.model')\n",
    "pickle_path = os.path.join('saved/pickles', 'lstm.pickle')\n",
    "\n",
    "# def check_data():\n",
    "#     if os.path.isfile(pickle_path):\n",
    "#         print('Loading data from pickle...')\n",
    "#         with open(pickle_path, 'rb') as f:\n",
    "#             return pickle.load(f)\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} The first dimension of paddings must be the rank of inputs[4,2] [1,16,36] [Op:Pad]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m n_channels \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[39m# Dilate the signal\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m dilated, pad_elements \u001b[39m=\u001b[39m signal_to_dilated(signal, dilation, n_channels)\n\u001b[0;32m     51\u001b[0m \u001b[39m# Print the dilated signal\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39mprint\u001b[39m(dilated)\n",
      "Cell \u001b[1;32mIn [4], line 12\u001b[0m, in \u001b[0;36msignal_to_dilated\u001b[1;34m(signal, dilation, n_channels)\u001b[0m\n\u001b[0;32m      9\u001b[0m pad_elements \u001b[39m=\u001b[39m dilation \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m (shape[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m dilation \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m dilation\n\u001b[0;32m     11\u001b[0m \u001b[39m# Pad the tensor to make its length a multiple of the dilation factor\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m dilated \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mpad(signal, [[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], [\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], [\u001b[39m0\u001b[39;49m, pad_elements], [\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m]])\n\u001b[0;32m     14\u001b[0m \u001b[39m# Reshape the tensor to have a dilation dimension\u001b[39;00m\n\u001b[0;32m     15\u001b[0m dilated \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(dilated, [shape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, dilation, n_channels])\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} The first dimension of paddings must be the rank of inputs[4,2] [1,16,36] [Op:Pad]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the function to dilate a tensor\n",
    "def signal_to_dilated(signal, dilation, n_channels):\n",
    "    # Get the shape of the tensor\n",
    "    shape = tf.shape(signal)\n",
    "\n",
    "    # Calculate the number of padding elements\n",
    "    pad_elements = dilation - 1 - (shape[2] + dilation - 1) % dilation\n",
    "\n",
    "    # Pad the tensor to make its length a multiple of the dilation factor\n",
    "    dilated = tf.pad(signal, [[0, 0], [0, 0], [0, pad_elements], [0, 0]])\n",
    "\n",
    "    # Reshape the tensor to have a dilation dimension\n",
    "    dilated = tf.reshape(dilated, [shape[0], -1, dilation, n_channels])\n",
    "\n",
    "    # Transpose the tensor to make the dilation dimension the second dimension\n",
    "    dilated = tf.transpose(dilated, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # Return the dilated tensor and the number of padding elements\n",
    "    return dilated, pad_elements\n",
    "\n",
    "# Define the input tensor\n",
    "signal = tf.constant([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2 , 3,4,7,8,3,9,1,0,0,2,20,2,1,1,104,202,2,56,53,21,76,2,6,4,56],\n",
    "                      ])\n",
    "signal = tf.expand_dims(signal, 0)\n",
    "# Define the dilation factor\n",
    "dilation = 2\n",
    "\n",
    "# Define the number of channels\n",
    "n_channels = 2\n",
    "\n",
    "# Dilate the signal\n",
    "dilated, pad_elements = signal_to_dilated(signal, dilation, n_channels)\n",
    "\n",
    "# Print the dilated signal\n",
    "print(dilated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
