{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "# throw error if files exists\n",
    "\n",
    "\n",
    "raw_data_dir = 'E:\\dataset'\n",
    "pwd = os.getcwd()\n",
    "seed = 69\n",
    "limit = 200\n",
    "\n",
    "# stft params\n",
    "sr = 44100\n",
    "n_fft = 1024\n",
    "h = int(n_fft/2)\n",
    "# direcoties\n",
    "noised_data_dir = os.path.join(raw_data_dir, 'noisyreverb')\n",
    "clean_data_dir = os.path.join(raw_data_dir , 'clean')\n",
    "# print(noised_data_dir)\n",
    "# data = np.empty(shape=(100,2),dtype=str)\n",
    "selected_files = {}\n",
    "np.random.seed(seed)\n",
    "while len(selected_files) < limit:\n",
    "    # collect 100 random unique files from noisyreverb\n",
    "    # print(clean_data_dir.)\n",
    "    max = len(os.listdir(noised_data_dir))\n",
    "    rand_index = np.random.randint(0,max)\n",
    "    while rand_index in selected_files:\n",
    "        rand_index = np.random.randint(0,max)\n",
    "    random_file = os.listdir(noised_data_dir)[rand_index]\n",
    "    assert random_file in os.listdir(clean_data_dir)\n",
    "    selected_files[rand_index] = random_file\n",
    "# print(selected_files.values())\n",
    "wav_files = list(selected_files.values())\n",
    "X = np.empty(shape=(len(wav_files)),dtype=object)\n",
    "Y = np.empty(shape=(len(wav_files)),dtype=object)\n",
    "# print(wav_files)\n",
    "for n, file_name in enumerate(wav_files):\n",
    "    clean_file = os.path.join(clean_data_dir, file_name)\n",
    "    noise_file = os.path.join(noised_data_dir, file_name)\n",
    "    clean_signal, _ = librosa.load(clean_file, sr=sr)\n",
    "    noise_signal, _ = librosa.load(noise_file, sr=sr)\n",
    "    assert clean_signal.shape == noise_signal.shape\n",
    "    clean_spec = librosa.stft(clean_signal, n_fft=n_fft, hop_length=h)\n",
    "    noised_spec = librosa.stft(noise_signal, n_fft=n_fft, hop_length=h)\n",
    "    assert clean_spec.shape == noised_spec.shape\n",
    "    X[n] = noised_spec\n",
    "    # print(X[n].shape)\n",
    "    Y[n] = clean_spec\n",
    "    # print(Y[n].shape)\n",
    "    # break\n",
    "np.save(f'X_{seed}_{limit}.npy', X)\n",
    "np.save(f'Y_{seed}_{limit}.npy', Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "dim_0 = 200\n",
    "dim_1 = 513\n",
    "X = np.empty(shape=(200,), dtype=object)\n",
    "pyX = []\n",
    "for i in range(200):\n",
    "    val = np.random.rand(dim_1, np.random.randint(200,400))+1j\n",
    "    X[i] = val\n",
    "    pyX.append(val)\n",
    "    # print(X[i].dtype)\n",
    "# grab the size of the 2nd dimension of each sample and store it in a list\n",
    "rowbreaks = [x.shape[1] for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pack_N_200_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [513,276] != values[1].shape = [513,317] [Op:Pack] name: values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m X_tf \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mpad(x, [[\u001b[39m0\u001b[39m, max_length \u001b[39m-\u001b[39m tf\u001b[39m.\u001b[39mshape(x)[\u001b[39m0\u001b[39m]], [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]]) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_tf]\n\u001b[0;32m      4\u001b[0m row_lengths \u001b[39m=\u001b[39m [[x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_tf]\n\u001b[1;32m----> 5\u001b[0m ragged_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mRaggedTensor\u001b[39m.\u001b[39;49mfrom_nested_row_lengths(X_tf, nested_row_lengths\u001b[39m=\u001b[39;49mrow_lengths, validate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pack_N_200_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [513,276] != values[1].shape = [513,317] [Op:Pack] name: values"
     ]
    }
   ],
   "source": [
    "X_tf = [tf.constant(x) for x in X]\n",
    "max_length = tf.reduce_max([tf.shape(x)[0] for x in X_tf])\n",
    "X_tf = [tf.pad(x, [[0, max_length - tf.shape(x)[0]], [0, 0]]) for x in X_tf]\n",
    "row_lengths = [[x.shape[1]] for x in X_tf]\n",
    "ragged_tensor = tf.RaggedTensor.from_nested_row_lengths(X_tf, nested_row_lengths=row_lengths, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([200, None, None])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, create a list of tensors with the desired shapes\n",
    "X_tf = [tf.random.normal((513, dim_2)) for dim_2 in range(200, 400)]\n",
    "\n",
    "# Then, use `tf.ragged.stack` to stack the tensors into a ragged tensor\n",
    "ragged_tensor = tf.ragged.stack(X_tf)\n",
    "\n",
    "# Finally, verify that the ragged tensor has the desired shape\n",
    "# assert ragged_tensor.shape == (200, 513, None)\n",
    "ragged_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## None of these work\n",
    "tr = [tf.constant(x) for x in X] # TensorShape([513, (dim_2)])\n",
    "# tx = tf.ragged.constant(pylist=tr, inner_shape=[513,None], ragged_rank=1,) # Doesn't terminate\n",
    "# tx = tf.ragged.constant(pylist=tr, ragged_rank=1) # Doesn't Terminate \n",
    "# tx = tf.ragged.constant(pylist=tr, inner_shape=[513,None]) # Doesn't terminate\n",
    "# tx = tf.RaggedTensor.from_row_lengths(values=tr, row_lengths=rowbreaks) # values[0].shape = [513,351] != values[1].shape = [513,202]\n",
    "# tx = tf.RaggedTensor.from_uniform_row_length(values=[tf.transpose(t) for t in tr], uniform_row_length=513, nrows=200 ) # shapes neq too in value\n",
    "# tx = tf.RaggedTensor.from_uniform_row_length(values=[tf.transpose(t) for t in tr], uniform_row_length=513)# neq shapes in \"value\" \n",
    "# tx = tf.RaggedTensor.from_tensor(tensor=tf.stack(tr, axis=0), ragged_rank=1) # neq shapes trying to stack\n",
    "# tx = tf.RaggedTensor.from_tensor(tensor=tf.stack(tr), lengths=rowbreaks) # Dst tensor is not initialized\n",
    "# tx = tf.RaggedTensor.from_tensor(tf.ragged.stack(tr, axis=0)) # object of type 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_tensor(tensor=tf.ragged.stack(tr), lengths=rowbreaks) # Dst tensor is not initialized\n",
    "# tx = tf.RaggedTensor.from_tensor(tr, ragged_rank=1) # neq shapes in Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr = [tf.ragged.constant(tf.stack(x)) for x in X] # Crashed after 4 minutes. Scalar tensor has no `len()`\n",
    "tr = [tf.ragged.constant(x) for x in X] #\n",
    "#If a ragged tensor can be defined using one or more ragged tensors with a uniform row length. Then we should be able to make 513xNone Ragged tensors for the stfts by stacking each frequency bin as row which should be a ragged tensor itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen():\n",
    "    for x in X:\n",
    "        x_ragged = tf.ragged.stack(x.tolist(), axis=0)\n",
    "        print(x_ragged.shape, x_ragged.dtype, type(x_ragged))\n",
    "        yield x\n",
    "dataset = tf.data.Dataset.from_generator(generator=gen, output_signature=tf.TensorSpec(shape=(513, None), dtype=np.complex128))\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tx = tf.RaggedTensor.from_tensor(tf.stack(tr, axis=0), ragged_rank=1) # neq shapes trying to stack\n",
    "# tx = tf.RaggedTensor.from_tensor(tf.ragged.stack(tr, axis=0)) # object of type 'RaggedTensor' has no len()\n",
    "# tx = tf.ragged.constant(pylist=tr, inner_shape=[None,513]) # 'RaggedTensor' has no len()\n",
    "# tx = tf.ragged.constant(pylist=tr) # 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_row_lengths(tr,row_lengths=[x.shape[1] for x in tr]) # Fails converting None to Tensor\n",
    "# tx = tf.RaggedTensor.from_row_lengths(tr,row_lengths=rowbreaks) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_nested_row_lengths(tr, nested_row_lengths=[tf.fill(dims=[513,],value=l ) for l in rowbreaks]) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_uniform_row_length([tf.transpose(t) for t in tr], uniform_row_length=513) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_tensor(tensor=tf.stack(tr), ragged_rank=1) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_tensor(tensor=tf.stack(tr)) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_tensor(tf.stack(tr), lengths=rowbreaks) # Fails: 'RaggedTensor' has no len()\n",
    "mid = tf.ragged.stack(tr, axis=0)\n",
    "# tx = tf.RaggedTensor.from_tensor(mid, ragged_rank=1) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_tensor(mid) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_tensor(mid, lengths=rowbreaks) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_row_lengths(mid,row_lengths=rowbreaks) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.RaggedTensor.from_nested_row_lengths(mid, nested_row_lengths=[tf.fill(dims=[513,],value=l ) for l in rowbreaks]) # Fails: Differing dtypes\n",
    "# tx = tf.RaggedTensor.from_uniform_row_length([tf.transpose(t) for t in mid], uniform_row_length=513) # Fails: 'RaggedTensor' has no len()\n",
    "# tx = tf.ragged.constant(mid, inner_shape=[513, None]) # pylist may not be a RaggedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This works but the shape is not proper\n",
    "import tensorflow as tf\n",
    "tr = [tf.constant(x) for x in X] # TensorShape([513, (dim_2)])\n",
    "tx = tf.ragged.stack(tr)# TensorShape([200, 513, (dim_2)])\n",
    "print(tx.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
