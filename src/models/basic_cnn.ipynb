{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(os.getcwd())\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "X = np.load(os.path.join(data_path, 'X_69_200.npy'), allow_pickle=True)\n",
    "# reshape X to be [n][f][t] f is frequency, t is time of the stft\n",
    "freq_bins = X[0].shape[0]\n",
    "data_size = X.shape[0]\n",
    "# X = np.reshape(X, newshape=(data_size, nfft_bins,None ))\n",
    "print(data_size, freq_bins)\n",
    "Y = np.load(os.path.join(data_path, 'Y_69_200.npy'), allow_pickle=True)\n",
    "# create tensor shape (data_size, nfft_bins, None) for X\n",
    "\n",
    "# X = tf.ragged.constant(X)\n",
    "# Y = tf.ragged.constant(Y)\n",
    "# [print(x.shape, x.dtype, type(x)) for x in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = [tf.RaggedTensor.from_tensor(x, ragged_rank=1) for x in X]\n",
    "Y = [tf.RaggedTensor.from_tensor(y, ragged_rank=1) for y in Y]\n",
    "splits = train_test_split(X, Y, test_size=0.2, random_state=69)\n",
    "# test = [tf.RaggedTensor.from_uniform_row_length(x, uniform_row_length=freq_bins).flat_values for x in splits[0]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = splits\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TakeDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m dataset\u001b[39m.\u001b[39melement_spec\n\u001b[0;32m     17\u001b[0m res \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m res[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TakeDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for idx in range(X.shape[0]):\n",
    "        x = X[idx]\n",
    "        y = Y[idx]\n",
    "        x_ragged = tf.ragged.stack(x.tolist(), axis=0)\n",
    "        y_ragged = tf.ragged.stack(y.tolist(), axis=0)\n",
    "        # print(x_ragged.shape, x_ragged.dtype, type(x_ragged))\n",
    "        yield x_ragged, y_ragged\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "     \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(513, None), dtype=np.complex64), \n",
    "        tf.TensorSpec(shape=(513, None), dtype=np.complex64)))\n",
    "# dataset.batch(128).repeat()\n",
    "dataset.element_spec\n",
    "res = dataset.(1)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalizationV2, GlobalMaxPooling2D\n",
    "from keras.layers import Flatten, Dropout, AveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import adam_v2\n",
    "from keras import layers\n",
    "import keras\n",
    "\n",
    "# import rms prop from keras\n",
    "# A Keras tensor is a symbolic tensor-like object, which we augment with certain attributes that allow us to build a Keras model just by knowing the inputs and outputs of the model.\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "opt = adam_v2.Adam(learning_rate=0.0007)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "\n",
    "# inputs are 2d arrays of shape [nfft_bins, time], time is a varried\n",
    "lookahead = 1\n",
    "frequency_bins = X[0].shape[0]\n",
    "data_shape = (frequency_bins, None)\n",
    "model_input = layers.Input(shape=(frequency_bins, None), dtype=tf.complex64)\n",
    "print(model_input.shape)\n",
    "# add channel dimension\n",
    "x_imag = tf.math.imag(model_input)\n",
    "# print(x_imag.shape)\n",
    "x = tf.abs(model_input)\n",
    "x = tf.expand_dims(x, axis=-1)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(frequency_bins//4,1),  padding='same', activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(frequency_bins//2,1),  padding='same', activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1,1), padding='same', activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = layers.Conv2D(filters=32, kernel_size=(frequency_bins//2,1),  padding='same', activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(frequency_bins//4,1),  padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(filters=1, kernel_size=(1,1),  padding='same', activation='relu')(x)\n",
    "# x = layers.GlobalMaxPooling2D(keepdims=True)(x)\n",
    "# out = Dense(frequency_bins, activation=\"relu\")(x)\n",
    "x = tf.squeeze(x, axis=-1)\n",
    "out = tf.complex(x, x_imag)\n",
    "model = keras.Model(inputs=model_input, outputs=out)\n",
    "model.summary()\n",
    "model.compile(loss='mse',\n",
    "              optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# model.add(BatchNormalizationV2())\n",
    "\n",
    "# model.add(GlobalMaxPooling2D())\n",
    "# model.add(Flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle(1000).batch(128)\n",
    "cnnhistory=model.fit(dataset, epochs=200, callbacks=[es], verbose=2, steps_per_epoch=100, bat)\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'one_shot_iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X, Y \u001b[39m=\u001b[39m gen()\u001b[39m.\u001b[39;49mone_shot_iterator()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'one_shot_iterator'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
