{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skeleton for future Training Dataset pipeline generator\n",
    "\n",
    "# TODO: Create split_spectrogram_frames function to split the spectrogram frames into fixed length sequences\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy.signal import stft\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "TARGET_SAMPLE_RATE = 16000\n",
    "TARGET_FEATURE = \"signal\" # \"stft\" or \"signal\"\n",
    "FEATURE_LENGTHS = 128 # width of the spectrogram images when using \"stft\" as feature\n",
    "OUTPUT_SEQUENCES = True\n",
    "\n",
    "def split_spectrogram_frames(spectrogram_frames: np.ndarray or list, sequence_length=128):\n",
    "    \"\"\"Split the spectrogram to sequences of fixed length.\n",
    "    Args:\n",
    "        spectrogram_frames (np.array): The spectrogram frames.\n",
    "        sequence_length (int): The length of the sequence.\n",
    "    Returns:\n",
    "        np.ndarray: The spectrogram sequences. Shape: (num_sequences, freq_bins, sequence_length)\n",
    "    \"\"\"\n",
    "    if isinstance(spectrogram_frames, list):\n",
    "        spectrogram_frames = np.array(spectrogram_frames)\n",
    "        # if is not NxM, raise error\n",
    "        if len(spectrogram_frames.shape) != 2:\n",
    "            raise ValueError(\"spectrogram_frames must be a 2D array\")\n",
    "    num_subsequences = spectrogram_frames.shape[1] // sequence_length\n",
    "    # Create an array of the appropriate shape to hold the sub-sequences\n",
    "    subsequences = np.zeros((spectrogram_frames.shape[0], num_subsequences, sequence_length))\n",
    "    # Loop through the rows of the array\n",
    "    for i in range(spectrogram_frames.shape[0]):\n",
    "        # Loop through the sub-sequences\n",
    "        for j in range(num_subsequences):\n",
    "        # Extract the current sub-sequence and store it in the appropriate place in the subsequences array\n",
    "            single_split = spectrogram_frames[i, j*sequence_length:(j+1)*sequence_length]\n",
    "            if single_split.shape[0] != sequence_length:\n",
    "                subsequences[i, j, :] = single_split\n",
    "            \n",
    "    # Return the subsequences array\n",
    "    return subsequences\n",
    "\n",
    "\n",
    "\n",
    "# # List all the files in the clean and distorted speech directories\n",
    "# clean_speech_files = os.listdir(clean_speech_dir)\n",
    "# distorted_speech_files = os.listdir(distorted_speech_dir)\n",
    "\n",
    "# assert len(clean_speech_files) == len(distorted_speech_files), 'The number of clean and distorted speech files must be the same.'\n",
    "\n",
    "# Loop through the clean and distorted speech files\n",
    "dataset = []\n",
    "def create_dataset(clean_speech_dir, distorted_speech_dir, seed=42, file_limit=None):\n",
    "    selected_files = {}\n",
    "    np.random.seed(seed)\n",
    "    while len(selected_files) < file_limit:\n",
    "        # collect `limit` random unique files from distorted_speech_dir\n",
    "        max = len(os.listdir(distorted_speech_dir))\n",
    "        rand_index = np.random.randint(0,max)\n",
    "\n",
    "        while rand_index in selected_files:\n",
    "            rand_index = np.random.randint(0,max)\n",
    "        \n",
    "        random_file = os.listdir(distorted_speech_dir)[rand_index]\n",
    "        assert random_file in os.listdir(clean_speech_dir)\n",
    "        selected_files[rand_index] = random_file\n",
    "    wav_files = list(selected_files.values())\n",
    "    # for clean_speech_file, distorted_speech_file in zip(clean_speech_files, distorted_speech_files):\n",
    "    for clean_speech_file, distorted_speech_file in zip(wav_files, wav_files):\n",
    "        assert clean_speech_file == distorted_speech_file, 'The clean and distorted speech files must have the same name and same order.'\n",
    "        # Read and load the clean and distorted audio files\n",
    "        clean_speech, _ = sf.read(os.path.join(clean_speech_dir, clean_speech_file))\n",
    "        distorted_speech, _ = sf.read(os.path.join(distorted_speech_dir, distorted_speech_file))\n",
    "        \n",
    "        \n",
    "        # Split the spectrogram frames into overlapping sequences of fixed length \n",
    "        if TARGET_FEATURE == \"stft\" :\n",
    "        # Apply the STFT to the audio samples to get the spectrogram frames\n",
    "            clean_speech_frames = stft(clean_speech)\n",
    "            distorted_speech_frames = stft(clean_speech)\n",
    "            inputs_sequences = split_spectrogram_frames(distorted_speech_frames, sequence_length=128)\n",
    "            targets_sequences = split_spectrogram_frames(clean_speech_frames, sequence_length=128)\n",
    "            assert inputs_sequences.shape == targets_sequences.shape, 'Split training and target stft must have the same shape.'\n",
    "        \n",
    "        # Create a data generator using the Timeseries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'E:\\dataset'\n",
    "pwd = os.getcwd()\n",
    "seed = 4242 # random seed\n",
    "limit = 100 # number of files to be used for training\n",
    "noised_data_dir = os.path.join(base_dir, 'noisy')\n",
    "clean_data_dir = os.path.join(base_dir , 'clean')\n",
    "# Generate random files to be used for training\n",
    "dataset = create_dataset(clean_data_dir, noised_data_dir, seed=seed, file_limit=limit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
