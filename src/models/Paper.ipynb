{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be signal in signal out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.slim as slim\n",
    "from keras import layers\n",
    "import keras as keras\n",
    "\n",
    "# LEAKY RELU UNIT\n",
    "# “pointwise nonlinear leaky rectified linear unit (LReLU) [28] max(0.2x, x)” \n",
    "# ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) \n",
    "# ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=9QWWB82R))\n",
    "def LeakyReLU(x):\n",
    "    return tf.maximum(0.2*x,x)\n",
    "\n",
    "# GENERATE DILATED LAYER FROM 1D SIGNAL\n",
    "def signal_to_dilated(signal, dilation, n_channels):\n",
    "    shape = tf.shape(signal)\n",
    "    pad_elements = dilation - 1 - (shape[2] + dilation - 1) % dilation\n",
    "    dilated = tf.pad(signal, [[0, 0], [0, 0], [0, pad_elements], [0, 0]])\n",
    "    dilated = tf.reshape(dilated, [shape[0],-1,dilation,n_channels])\n",
    "    return tf.transpose(dilated, perm=[0,2,1,3]), pad_elements\n",
    "\n",
    "\n",
    "# COLLAPSE DILATED LAYER TO 1D SIGNAL\n",
    "def dilated_to_signal(dilated, pad_elements, n_channels):\n",
    "    shape = tf.shape(dilated)\n",
    "    signal = tf.transpose(dilated, perm=[0,2,1,3])\n",
    "    signal = tf.reshape(signal, [shape[0],1,-1,n_channels])\n",
    "    return signal[:,:,:shape[1]*shape[2]-pad_elements,:]\n",
    "\n",
    "\n",
    "# ADAPTIVE BATCH NORMALIZATION LAYER\n",
    "#b) Adaptive normalization:\n",
    "def AdaptiveNormalization(x):\n",
    "    alpha=tf.Variable(1.0,name='alpha')\n",
    "    beta=tf.Variable(0.0,name='beta')\n",
    "    return alpha*x + beta*layers.BatchNormalization(x)\n",
    "\n",
    "\n",
    "# IDENTITY INITIALIZATION OF CONV LAYERS\n",
    "def identity_initializer():\n",
    "    def _initializer(shape, dtype=tf.float32, partition_info=None):\n",
    "        array = np.zeros(shape, dtype=float)\n",
    "        cx, cy = shape[0]//2, shape[1]//2\n",
    "        for i in range(np.minimum(shape[2],shape[3])):\n",
    "            array[cx, cy, i, i] = 1\n",
    "        return tf.constant(array, dtype=dtype)\n",
    "    return _initializer\n",
    "\n",
    "\n",
    "# “In our experiments, simple training losses (e.g., L1) led to noticeably degraded output quality at lower signal-to-noise ratios (SNRs).” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=DZN467TR))\n",
    "def loss_function(target, current, type):\n",
    "    if type == 'L1':\n",
    "        return tf.reduce_mean(tf.abs(target-current))\n",
    "    elif type == 'L2':\n",
    "        return tf.reduce_mean(tf.square(target-current))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“To compute the loss between two waveforms, we apply a pretrained audio classification network to each waveform and compare the internal activation patterns induced in the network by the two signals” ([Germain et al., 2018, p. 1](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=1&annotation=Y3F49L4C))\n",
    "\n",
    "“The network consists of 15 convolutional layers with 3×1 kernels, batch normalization, LReLU units, and zero padding” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=J3JNI54Q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE LOSS NETWORK\n",
    "import keras as keras\n",
    "def LossNetwork(input, n_layers=14, training=True, reuse=False, norm_type=\"SBN\"):\n",
    "    # “The number of channels is doubled every 5 layers, with 32 channels in the first intermediate layer.” \n",
    "    base_channels=32\n",
    "    doubling_rate=5\n",
    "    conv_layers = []\n",
    "    if norm_type == \"NM\": # ADAPTIVE BATCH NORM\n",
    "        norm_fn = AdaptiveNormalization\n",
    "    elif norm_type == \"SBN\": # BATCH NORM\n",
    "        norm_fn = layers.BatchNormalization\n",
    "    else: # NO LAYER NORMALIZATION\n",
    "        norm_fn = None\n",
    "        \n",
    "    for current_layer in range(n_layers):\n",
    "        n_channels = base_channels * (2 ** (current_layer // doubling_rate)) # UPDATE CHANNEL COUNT\n",
    "        if current_layer == 0:\n",
    "            # \"Each Layer is decimated by 2\" - just means stride of 2 in the time dimension.\n",
    "            net = layers.Conv2D(input, n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn, stride=[1, 2],\n",
    "                              scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "        elif current_layer < n_layers - 1:\n",
    "            net = layers.Conv2D(layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                              stride=[1, 2], scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "        else:\n",
    "            net = layers.Conv2D(layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                              scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "\n",
    "    return conv_layers\n",
    "\n",
    "\n",
    "def featureloss(target, current, loss_weights, loss_layers, n_layers=14, norm_type=\"SBN\", base_channels=32, blk_channels=5):\n",
    "\n",
    "    feat_current = LossNetwork(current, reuse=False, n_layers=n_layers, norm_type=norm_type)\n",
    "\n",
    "    feat_target = LossNetwork(target, reuse=True, n_layers=n_layers, norm_type=norm_type,\n",
    "                         base_channels=base_channels, blk_channels=blk_channels)\n",
    "\n",
    "    loss_vec = [0]\n",
    "    for id in range(loss_layers):\n",
    "        loss_vec.append(loss_function(feat_current[id], feat_target[id], type=\"L1\") / loss_weights[id])\n",
    "\n",
    "    for id in range(1,loss_layers+1):\n",
    "        loss_vec[0] += loss_vec[id]\n",
    "\n",
    "    return loss_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“receptive field of the pipeline is 2^14 + 1 samples, i.e., about 1 s of audio for fs = 16 kHz.” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=WTGLQ8JQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context aggregation MODULE:\n",
    "# ENHANCEMENT NETWORK\n",
    "def senet(input, n_layers=13, training=True, reuse=False, norm_type=\"NM\", n_channels=32):\n",
    "    # ksz = kernel size\n",
    "    # n_channels = number of feature maps in paper (64 in paper)\n",
    "    if norm_type == \"NM\": # ADAPTIVE BATCH NORM\n",
    "        norm_fn = AdaptiveNormalization\n",
    "    elif norm_type == \"SBN\": # BATCH NORM\n",
    "        norm_fn = layers.BatchNormalization\n",
    "    else: # NO LAYER NORMALIZATION\n",
    "        norm_fn = None\n",
    "\n",
    "    for current_layer in range(n_layers):\n",
    "\n",
    "        if current_layer == 0:\n",
    "            net = layers.Conv2D(input, n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU,\n",
    "                              normalizer_fn=norm_fn, scope='se_conv_%d' % current_layer,\n",
    "                              padding='SAME', reuse=reuse)\n",
    "        else:\n",
    "            # The content of each intermediate layer is computed from the previous layer via a dilated convolution with 3 × 1 convolutional kernels\n",
    "            # “Here, we increase the dilation factor exponentially with depth from 2^0 for the 1st intermediate layer to 2^12 for the 13th one.” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=53YMMHY2))\n",
    "            dilation_factor = 2 ** current_layer\n",
    "            net, pad_elements = signal_to_dilated(net, n_channels=n_channels, dilation=dilation_factor)\n",
    "            net = layers.Conv2D(net, n_channels, kernel_size=[1, 3], activation=LeakyReLU,\n",
    "                              normalizer_fn=norm_fn, scope='se_conv_%d' % current_layer,\n",
    "                              padding='SAME', reuse=reuse)\n",
    "            net = dilated_to_signal(net, n_channels=n_channels, pad_elements=pad_elements)\n",
    "\n",
    "    net = layers.Conv2D(net, n_channels, kernel_size=[1, 3], activation=LeakyReLU,\n",
    "                      normalizer_fn=norm_fn, scope='se_conv_last',\n",
    "                      padding='SAME', reuse=reuse)\n",
    "\n",
    "    output = layers.Conv2D(net, 1, kernel_size=[1, 1], activation=None,\n",
    "                         scope='se_fc_last', padding='SAME', reuse=reuse)\n",
    "\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
