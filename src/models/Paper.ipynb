{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be signal in signal out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.slim as slim\n",
    "from keras import layers\n",
    "import keras as keras\n",
    "\n",
    "# LEAKY RELU UNIT\n",
    "# “pointwise nonlinear leaky rectified linear unit (LReLU) [28] max(0.2x, x)” \n",
    "# ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) \n",
    "# ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=9QWWB82R))\n",
    "def LeakyReLU(x):\n",
    "    return tf.maximum(0.2*x,x)\n",
    "\n",
    "# GENERATE DILATED LAYER FROM 1D SIGNAL\n",
    "def signal_to_dilated(signal, dilation, n_channels):\n",
    "    shape = tf.shape(signal)\n",
    "    pad_elements = dilation - 1 - (shape[2] + dilation - 1) % dilation\n",
    "    dilated = tf.pad(signal, [[0, 0], [0, 0], [0, pad_elements], [0, 0]])\n",
    "    dilated = tf.reshape(dilated, [shape[0],-1,dilation,n_channels])\n",
    "    return tf.transpose(dilated, perm=[0,2,1,3]), pad_elements\n",
    "\n",
    "\n",
    "# COLLAPSE DILATED LAYER TO 1D SIGNAL\n",
    "def dilated_to_signal(dilated, pad_elements, n_channels):\n",
    "    shape = tf.shape(dilated)\n",
    "    signal = tf.transpose(dilated, perm=[0,2,1,3])\n",
    "    signal = tf.reshape(signal, [shape[0],1,-1,n_channels])\n",
    "    return signal[:,:,:shape[1]*shape[2]-pad_elements,:]\n",
    "\n",
    "\n",
    "# ADAPTIVE BATCH NORMALIZATION LAYER\n",
    "#b) Adaptive normalization:\n",
    "def AdaptiveNormalization(x):\n",
    "    alpha=tf.Variable(1.0,name='alpha')\n",
    "    beta=tf.Variable(0.0,name='beta')\n",
    "    return alpha*x + beta*layers.BatchNormalization(x)\n",
    "\n",
    "\n",
    "# IDENTITY INITIALIZATION OF CONV LAYERS\n",
    "def identity_initializer():\n",
    "    def _initializer(shape, dtype=tf.float32, partition_info=None):\n",
    "        array = np.zeros(shape, dtype=float)\n",
    "        cx, cy = shape[0]//2, shape[1]//2\n",
    "        for i in range(np.minimum(shape[2],shape[3])):\n",
    "            array[cx, cy, i, i] = 1\n",
    "        return tf.constant(array, dtype=dtype)\n",
    "    return _initializer\n",
    "\n",
    "\n",
    "# “In our experiments, simple training losses (e.g., L1) led to noticeably degraded output quality at lower signal-to-noise ratios (SNRs).” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=DZN467TR))\n",
    "def loss_function(target, current, type):\n",
    "    if type == 'L1':\n",
    "        return tf.reduce_mean(tf.abs(target-current))\n",
    "    elif type == 'L2':\n",
    "        return tf.reduce_mean(tf.square(target-current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“To compute the loss between two waveforms, we apply a pretrained audio classification network to each waveform and compare the internal activation patterns induced in the network by the two signals” ([Germain et al., 2018, p. 1](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=1&annotation=Y3F49L4C))\n",
    "\n",
    "“The network consists of 15 convolutional layers with 3×1 kernels, batch normalization, LReLU units, and zero padding” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=J3JNI54Q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE LOSS NETWORK\n",
    "import keras as keras\n",
    "def LossNetwork(input, n_layers=14, training=True, reuse=False, norm_type=\"SBN\"):\n",
    "    # “The number of channels is doubled every 5 layers, with 32 channels in the first intermediate layer.” \n",
    "    base_channels=32\n",
    "    doubling_rate=5\n",
    "    conv_layers = []\n",
    "    if norm_type == \"NM\": # ADAPTIVE BATCH NORM\n",
    "        norm_fn = AdaptiveNormalization\n",
    "    elif norm_type == \"SBN\": # BATCH NORM\n",
    "        norm_fn = layers.BatchNormalization\n",
    "    else: # NO LAYER NORMALIZATION\n",
    "        norm_fn = None\n",
    "        \n",
    "    for current_layer in range(n_layers):\n",
    "        n_channels = base_channels * (2 ** (current_layer // doubling_rate)) # UPDATE CHANNEL COUNT\n",
    "        if current_layer == 0:\n",
    "            # \"Each Layer is decimated by 2\" - just means stride of 2 in the time dimension.\n",
    "            net = layers.Conv2D(input, n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn, stride=[1, 2],\n",
    "                              scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "        elif current_layer < n_layers - 1:\n",
    "            net = layers.Conv2D(conv_layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                              stride=[1, 2], scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "        else:\n",
    "            net = layers.Conv2D(conv_layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                              scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "\n",
    "    return conv_layers\n",
    "\n",
    "\n",
    "def featureloss(target, current, loss_weights, loss_layers, n_layers=14, norm_type=\"SBN\", base_channels=32, blk_channels=5):\n",
    "\n",
    "    feat_current = LossNetwork(current, reuse=False, n_layers=n_layers, norm_type=norm_type)\n",
    "\n",
    "    feat_target = LossNetwork(target, reuse=True, n_layers=n_layers, norm_type=norm_type,\n",
    "                         base_channels=base_channels, blk_channels=blk_channels)\n",
    "\n",
    "    loss_vec = [0]\n",
    "    for id in range(loss_layers):\n",
    "        loss_vec.append(loss_function(feat_current[id], feat_target[id], type=\"L1\") / loss_weights[id])\n",
    "\n",
    "    for id in range(1,loss_layers+1):\n",
    "        loss_vec[0] += loss_vec[id]\n",
    "\n",
    "    return loss_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“receptive field of the pipeline is 2^14 + 1 samples, i.e., about 1 s of audio for fs = 16 kHz.” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=WTGLQ8JQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context aggregation MODULE:\n",
    "# ENHANCEMENT NETWORK\n",
    "def senet(input, n_layers=13, training=True, reuse=False, norm_type=\"NM\", n_channels=32):\n",
    "    # ksz = kernel size\n",
    "    # n_channels = number of feature maps in paper (64 in paper)\n",
    "    if norm_type == \"NM\": # ADAPTIVE BATCH NORM\n",
    "        norm_fn = AdaptiveNormalization\n",
    "    elif norm_type == \"SBN\": # BATCH NORM\n",
    "        norm_fn = layers.BatchNormalization\n",
    "    else: # NO LAYER NORMALIZATION\n",
    "        norm_fn = None\n",
    "\n",
    "    for current_layer in range(n_layers):\n",
    "\n",
    "        if current_layer == 0:\n",
    "            net = layers.Conv2D(input, n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU,\n",
    "                              normalizer_fn=norm_fn, scope='se_conv_%d' % current_layer,\n",
    "                              padding='SAME', reuse=reuse)\n",
    "        else:\n",
    "            # The content of each intermediate layer is computed from the previous layer via a dilated convolution with 3 × 1 convolutional kernels\n",
    "            # “Here, we increase the dilation factor exponentially with depth from 2^0 for the 1st intermediate layer to 2^12 for the 13th one.” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=53YMMHY2))\n",
    "            dilation_factor = 2 ** current_layer\n",
    "            net, pad_elements = signal_to_dilated(net, n_channels=n_channels, dilation=dilation_factor)\n",
    "            net = layers.Conv2D(net, n_channels, kernel_size=[1, 3], activation=LeakyReLU,\n",
    "                              normalizer_fn=norm_fn, scope='se_conv_%d' % current_layer,\n",
    "                              padding='SAME', reuse=reuse)\n",
    "            net = dilated_to_signal(net, n_channels=n_channels, pad_elements=pad_elements)\n",
    "\n",
    "    net = layers.Conv2D(net, n_channels, kernel_size=[1, 3], activation=LeakyReLU,\n",
    "                      normalizer_fn=norm_fn, scope='se_conv_last',\n",
    "                      padding='SAME', reuse=reuse)\n",
    "\n",
    "    output = layers.Conv2D(net, 1, kernel_size=[1, 1], activation=None,\n",
    "                         scope='se_fc_last', padding='SAME', reuse=reuse)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list_variables() missing 1 required positional argument: 'ckpt_dir_or_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tf\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mlist_variables()\n",
      "\u001b[1;31mTypeError\u001b[0m: list_variables() missing 1 required positional argument: 'ckpt_dir_or_file'"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "import os\n",
    "\n",
    "import sys, getopt\n",
    "\n",
    "# Variables\n",
    "SE_LAYERS = 13 # NUMBER OF INTERNAL LAYERS\n",
    "SE_CHANNELS = 64 # NUMBER OF FEATURE CHANNELS PER LAYER\n",
    "SE_LOSS_LAYERS = 6 # NUMBER OF FEATURE LOSS LAYERS\n",
    "SE_NORM = \"NM\" # TYPE OF LAYER NORMALIZATION (NM, SBN or None)\n",
    "SE_LOSS_TYPE = \"FL\" # TYPE OF TRAINING LOSS (L1, L2 or FL)\n",
    "\n",
    "# FEATURE LOSS NETWORK\n",
    "LOSS_LAYERS = 14 # NUMBER OF INTERNAL LAYERS\n",
    "LOSS_BASE_CHANNELS = 32 # NUMBER OF FEATURE CHANNELS PER LAYER IN FIRT LAYER\n",
    "LOSS_BLK_CHANNELS = 5 # NUMBER OF LAYERS BETWEEN CHANNEL NUMBER UPDATES\n",
    "LOSS_NORM = \"SBN\" # TYPE OF LAYER NORMALIZATION (NM, SBN or None)\n",
    "\n",
    "\n",
    "SET_WEIGHT_EPOCH = 10 # NUMBER OF EPOCHS BEFORE FEATURE LOSS BALANCE\n",
    "SAVE_EPOCHS = 10 # NUMBER OF EPOCHS BETWEEN MODEL SAVES\n",
    "\n",
    "log_file = open(\"logfile.txt\", 'w+')\n",
    "\n",
    "# COMMAND LINE OPTIONS\n",
    "model_path = os.path.join('saved','models', 'fcnn.model')\n",
    "loss_model_path = os.path.join('saved','models', 'floss.model')\n",
    "data_path = os.path.join('data')\n",
    "datafolder = \"dataset\"\n",
    "modfolder = \"models\"\n",
    "checkpoint = callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,mode='min')\n",
    "# try:\n",
    "#     opts, args = getopt.getopt(sys.argv[1:],\"hd:l:o:\",[\"ifolder=,lossfolder=,outfolder=\"])\n",
    "# except getopt.GetoptError:\n",
    "#     print('Usage: python senet_infer.py -d <datafolder> -l <lossfolder> -o <outfolder>')\n",
    "#     sys.exit(2)\n",
    "# for opt, arg in opts:\n",
    "#     if opt == '-h':\n",
    "#         print ('Usage: python senet_infer.py -d <datafolder> -l <lossfolder> -o <outfolder>')\n",
    "#         sys.exit()\n",
    "#     elif opt in (\"-d\", \"--datafolder\"):\n",
    "#         datafolder = arg\n",
    "#     elif opt in (\"-l\", \"--lossfolder\"):\n",
    "#         modfolder = arg\n",
    "#     elif opt in (\"-o\", \"--outfolder\"):\n",
    "#         outfolder = arg\n",
    "# print( 'Data folder is \"' + datafolder + '/\"')\n",
    "# print ('Loss model folder is \"' + modfolder + '/\"')\n",
    "# print( 'Output model folder is \"' + outfolder + '/\"')\n",
    "\n",
    "# SET LOSS FUNCTIONS AND PLACEHOLDERS\n",
    "with tf.name_scope('loss_weights'):\n",
    "    input_tensor = layers.Input(shape=(None, 1, None, 1), dtype=tf.float32)\n",
    "    clean_tensor = layers.Input(shape=(None, 1, None, 1), dtype=tf.float32)\n",
    "    # input=tf.placeholder(tf.float32,shape=[None,1,None,1])\n",
    "    # clean=tf.placeholder(tf.float32,shape=[None,1,None,1])\n",
    "        \n",
    "    enhanced_tensor=senet(input_tensor, n_layers=SE_LAYERS, norm_type=SE_NORM, n_channels=SE_CHANNELS)\n",
    "    # enhanced=senet(input, n_layers=SE_LAYERS, norm_type=SE_NORM, n_channels=SE_CHANNELS)\n",
    "        \n",
    "    if SE_LOSS_TYPE == \"L1\" or SE_LOSS_TYPE == \"L2\": # L1 LOSS\n",
    "        # loss_weights = tf.placeholder(tf.float32, shape=[])\n",
    "        loss_tensor = layers.Input(shape=None, dtype=tf.float32)\n",
    "        loss_fn = loss_function(clean_tensor, enhanced_tensor, type=SE_LOSS_TYPE)\n",
    "    else: # FEATURE LOSS\n",
    "        # loss_weights = tf.placeholder(tf.float32, shape=[SE_LOSS_LAYERS])\n",
    "        loss_tensor = layers.Input(shape=(SE_LOSS_LAYERS), dtype=tf.float32)\n",
    "        # loss_fn = featureloss(clean, enhanced, loss_weights, loss_layers=SE_LOSS_LAYERS, n_layers=LOSS_LAYERS, norm_type=LOSS_NORM,\n",
    "        #                          base_channels=LOSS_BASE_CHANNELS, blk_channels=LOSS_BLK_CHANNELS)\n",
    "        \n",
    "        loss_fn = featureloss(clean_tensor, enhanced_tensor, loss_tensor, loss_layers=SE_LOSS_LAYERS, n_layers=LOSS_LAYERS, norm_type=LOSS_NORM,\n",
    "                                 base_channels=LOSS_BASE_CHANNELS, blk_channels=LOSS_BLK_CHANNELS)\n",
    "\n",
    "# LOAD DATA\n",
    "trainset, valset = load_full_data_list(datafolder = datafolder)\n",
    "trainset, valset = load_full_data(trainset, valset)\n",
    "\n",
    "# TRAINING OPTIMIZER\n",
    "opt=tf.train.AdamOptimizer(learning_rate=1e-4).\\\n",
    "    minimize(loss_fn[0],var_list=[var for var in tf.trainable_variables() if var.name.startswith(\"se_\")])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# BEGIN SCRIPT #########################################################################################################\n",
    "\n",
    "# INITIALIZE GPU CONFIG\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "print (\"Config ready\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print( \"Session initialized\")\n",
    "\n",
    "# LOAD FEATURE LOSS\n",
    "if SE_LOSS_TYPE == \"FL\":\n",
    "    loss_saver = tf.train.Saver([var for var in tf.trainable_variables() if var.name.startswith(\"loss_\")])\n",
    "    loss_saver.restore(sess, \"./%s/loss_model.ckpt\" % modfolder)\n",
    "\n",
    "Nepochs = 320\n",
    "saver = tf.train.Saver([var for var in tf.trainable_variables() if var.name.startswith(\"se_\")])\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "if SE_LOSS_TYPE == \"FL\":\n",
    "    loss_train = np.zeros((len(trainset[\"innames\"]),SE_LOSS_LAYERS+1))\n",
    "    loss_val = np.zeros((len(valset[\"innames\"]),SE_LOSS_LAYERS+1))\n",
    "else:\n",
    "    loss_train = np.zeros((len(trainset[\"innames\"]),1))\n",
    "    loss_val = np.zeros((len(valset[\"innames\"]),1))\n",
    "    \n",
    "if SE_LOSS_TYPE == \"FL\":\n",
    "    loss_w = np.ones(SE_LOSS_LAYERS)\n",
    "else:\n",
    "    loss_w = []\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "for epoch in range(1,Nepochs+1):\n",
    "\n",
    "    print(\"Epoch no.%d\"%epoch)\n",
    "    # TRAINING EPOCH ################################################################\n",
    "\n",
    "    ids = np.random.permutation(len(trainset[\"innames\"])) # RANDOM FILE ORDER\n",
    "\n",
    "    for id in tqdm(range(0, len(ids)), file=sys.stdout):\n",
    "\n",
    "        i = ids[id] # RANDOMIZED ITERATION INDEX\n",
    "        inputData = trainset[\"inaudio\"][i] # LOAD DEGRADED INPUT\n",
    "        outputData = trainset[\"outaudio\"][i] # LOAD GROUND TRUTH\n",
    "\n",
    "        # TRAINING ITERATION\n",
    "        _, loss_vec = sess.run([opt, loss_fn],\n",
    "                                feed_dict={input: inputData, clean: outputData, loss_weights: loss_w})\n",
    "\n",
    "        # SAVE ITERATION LOSS\n",
    "        loss_train[id,0] = loss_vec[0]\n",
    "        if SE_LOSS_TYPE == \"FL\":\n",
    "            for j in range(SE_LOSS_LAYERS):\n",
    "                loss_train[id,j+1] = loss_vec[j+1]\n",
    "\n",
    "    # PRINT EPOCH TRAINING LOSS AVERAGE\n",
    "    str = \"T: %d\\t \" % (epoch)\n",
    "    if SE_LOSS_TYPE == \"FL\":\n",
    "        for j in range(SE_LOSS_LAYERS+1):\n",
    "            str += \", %10.6e\"%(np.mean(loss_train, axis=0)[j])\n",
    "    else:\n",
    "        str += \", %10.6e\"%(np.mean(loss_train, axis=0)[0])\n",
    "\n",
    "    log_file.write(str + \"\\n\")\n",
    "    log_file.flush()\n",
    "\n",
    "    # SET WEIGHTS AFTER M EPOCHS\n",
    "    if SE_LOSS_TYPE == \"FL\" and epoch == SET_WEIGHT_EPOCH:\n",
    "        loss_w = np.mean(loss_train, axis=0)[1:]\n",
    "\n",
    "    # SAVE MODEL EVERY N EPOCHS\n",
    "    if epoch % SAVE_EPOCHS != 0:\n",
    "        continue\n",
    "\n",
    "    saver.save(sess, outfolder + \"/se_model.ckpt\")\n",
    "\n",
    "    # VALIDATION EPOCH ##############################################################\n",
    "\n",
    "    print(\"Validation epoch\")\n",
    "\n",
    "    for id in tqdm(range(0, len(valset[\"innames\"])), file=sys.stdout):\n",
    "\n",
    "        i = id # NON-RANDOMIZED ITERATION INDEX\n",
    "        inputData = valset[\"inaudio\"][i] # LOAD DEGRADED INPUT\n",
    "        outputData = valset[\"outaudio\"][i] # LOAD GROUND TRUTH\n",
    "\n",
    "        # VALIDATION ITERATION\n",
    "        output, loss_vec = sess.run([enhanced, loss_fn],\n",
    "                            feed_dict={input: inputData, clean: outputData, loss_weights: loss_w})\n",
    "\n",
    "        # SAVE ITERATION LOSS\n",
    "        loss_val[id,0] = loss_vec[0]\n",
    "        if SE_LOSS_TYPE == \"FL\":\n",
    "            for j in range(SE_LOSS_LAYERS):\n",
    "                loss_val[id,j+1] = loss_vec[j+1]\n",
    "\n",
    "    # PRINT VALIDATION EPOCH LOSS AVERAGE\n",
    "    str = \"V: %d \" % (epoch)\n",
    "    if SE_LOSS_TYPE == \"FL\":\n",
    "        for j in range(SE_LOSS_LAYERS+1):\n",
    "            str += \", %10.6e\"%(np.mean(loss_val, axis=0)[j]*1e9)\n",
    "    else:\n",
    "        str += \", %10.6e\"%(np.mean(loss_val, axis=0)[0]*1e9)\n",
    "\n",
    "    log_file.write(str + \"\\n\")\n",
    "    log_file.flush()\n",
    "\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
