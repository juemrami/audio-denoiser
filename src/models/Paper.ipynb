{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be signal in signal out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.slim as slim\n",
    "from keras import layers\n",
    "import keras as keras\n",
    "\n",
    "\n",
    "\n",
    "# GENERATE DILATED LAYER FROM 1D SIGNAL\n",
    "def signal_to_dilated(signal, dilation, n_channels):\n",
    "    shape = tf.shape(signal)\n",
    "    pad_elements = dilation - 1 - (shape[2] + dilation - 1) % dilation\n",
    "    dilated = tf.pad(signal, [[0, 0], [0, 0], [0, pad_elements], [0, 0]])\n",
    "    dilated = tf.reshape(dilated, [shape[0],-1,dilation,n_channels])\n",
    "    return tf.transpose(dilated, perm=[0,2,1,3]), pad_elements\n",
    "\n",
    "\n",
    "# COLLAPSE DILATED LAYER TO 1D SIGNAL\n",
    "def dilated_to_signal(dilated, pad_elements, n_channels):\n",
    "    shape = tf.shape(dilated)\n",
    "    signal = tf.transpose(dilated, perm=[0,2,1,3])\n",
    "    signal = tf.reshape(signal, [shape[0],1,-1,n_channels])\n",
    "    return signal[:,:,:shape[1]*shape[2]-pad_elements,:]\n",
    "\n",
    "\n",
    "# IDENTITY INITIALIZATION OF CONV LAYERS\n",
    "def identity_initializer():\n",
    "    def _initializer(shape, dtype=tf.float32, partition_info=None):\n",
    "        array = np.zeros(shape, dtype=float)\n",
    "        cx, cy = shape[0]//2, shape[1]//2\n",
    "        for i in range(np.minimum(shape[2],shape[3])):\n",
    "            array[cx, cy, i, i] = 1\n",
    "        return tf.constant(array, dtype=dtype)\n",
    "    return _initializer\n",
    "\n",
    "\n",
    "# “In our experiments, simple training losses (e.g., L1) led to noticeably degraded output quality at lower signal-to-noise ratios (SNRs).” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=DZN467TR))\n",
    "def loss_function(target, current, type):\n",
    "    if type == 'L1':\n",
    "        return tf.reduce_mean(tf.abs(target-current))\n",
    "    elif type == 'L2':\n",
    "        return tf.reduce_mean(tf.square(target-current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“To compute the loss between two waveforms, we apply a pretrained audio classification network to each waveform and compare the internal activation patterns induced in the network by the two signals” ([Germain et al., 2018, p. 1](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=1&annotation=Y3F49L4C))\n",
    "\n",
    "“The network consists of 15 convolutional layers with 3×1 kernels, batch normalization, LReLU units, and zero padding” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=J3JNI54Q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE LOSS NETWORK\n",
    "import keras as keras\n",
    "def LossNetwork(input, n_layers=14, training=True, reuse=False, norm_type=\"SBN\"):\n",
    "    # “The number of channels is doubled every 5 layers, with 32 channels in the first intermediate layer.” \n",
    "    base_channels=32\n",
    "    doubling_rate=5\n",
    "    conv_layers = []\n",
    "    if norm_type == \"NM\": # ADAPTIVE BATCH NORM\n",
    "        norm_fn = AdaptiveNormalization\n",
    "    elif norm_type == \"SBN\": # BATCH NORM\n",
    "        norm_fn = layers.BatchNormalization\n",
    "    else: # NO LAYER NORMALIZATION\n",
    "        norm_fn = None\n",
    "        \n",
    "    for current_layer in range(n_layers):\n",
    "        n_channels = base_channels * (2 ** (current_layer // doubling_rate)) # UPDATE CHANNEL COUNT\n",
    "        if current_layer == 0:\n",
    "            # \"Each Layer is decimated by 2\" - just means stride of 2 in the time dimension.\n",
    "            net = layers.Conv2D(input, n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn, stride=[1, 2],\n",
    "                              scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "        elif current_layer < n_layers - 1:\n",
    "            net = layers.Conv2D(conv_layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                              stride=[1, 2], scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "        else:\n",
    "            net = layers.Conv2D(conv_layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                              scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "            conv_layers.append(net)\n",
    "            # \"Each channel in the last layer is averaged-pooled to produce the output ferature vector.\"\n",
    "\n",
    "    return conv_layers\n",
    "\n",
    "\n",
    "def featureloss(target, current, loss_weights, loss_layers, n_layers=14, norm_type=\"SBN\", base_channels=32, blk_channels=5):\n",
    "\n",
    "    feat_current = LossNetwork(current, reuse=False, n_layers=n_layers, norm_type=norm_type)\n",
    "\n",
    "    feat_target = LossNetwork(target, reuse=True, n_layers=n_layers, norm_type=norm_type,\n",
    "                         base_channels=base_channels, blk_channels=blk_channels)\n",
    "\n",
    "    loss_vec = [0]\n",
    "    #“The weights λm are set to balance the contribution of each layer to the loss. They are set to the inverse of the relative values of ‖Φm(ß) − Φm(g(x; θ))‖1 after 10 training epochs. (For these first 10 epochs, the weights are set to 1.)”\n",
    "    for id in range(loss_layers):\n",
    "        loss_vec.append(loss_function(feat_current[id], feat_target[id], type=\"L1\") / loss_weights[id])\n",
    "    # b) Denoising loss function:\n",
    "    for id in range(1,loss_layers+1):\n",
    "        loss_vec[0] += loss_vec[id]\n",
    "\n",
    "    return loss_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“receptive field of the pipeline is 2^14 + 1 samples, i.e., about 1 s of audio for fs = 16 kHz.” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=WTGLQ8JQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-noising Network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "class AdaptiveNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdaptiveNormalization, self).__init__(**kwargs)\n",
    "        self.alpha = tf.Variable(1.0, name='alpha')\n",
    "        self.beta = tf.Variable(0.0, name='beta')\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
    "    def call(self, x):\n",
    "        return self.alpha * x + self.beta * self.batch_norm(x)\n",
    "# “point-wise nonlinear leaky rectified linear unit (LReLU) [28] max(0.2x, x)” \n",
    "# ([Germain et al., 2018, p. 2]\n",
    "def LeakyReLU(x):\n",
    "    return tf.maximum(0.2*x,x)\n",
    "\n",
    "n_layers=13 # num of internal layers\n",
    "training=True\n",
    "reuse=False\n",
    "norm_type=\"NM\"\n",
    "n_channels=32 # number of feature maps (64 in paper)\n",
    "if norm_type == \"NM\": # ADAPTIVE BATCH NORM\n",
    "    norm_fn = AdaptiveNormalization\n",
    "elif norm_type == \"SBN\": # BATCH NORM\n",
    "    norm_fn = layers.BatchNormalization\n",
    "else: # NO LAYER NORMALIZATION\n",
    "    norm_fn = None\n",
    "model_input = tf.keras.layers.Input(shape=(None, 1), dtype=tf.float32) # input is a single channel waveform (time, 1)\n",
    "input = tf.expand_dims(model_input, axis=-1) # add a conv feature dimension (batch, time, 1, features)\n",
    "input = tf.transpose(input, [0, 2, 1, 3]) # transpose to (batch, 1, time, features)\n",
    "for current_layer in range(n_layers):\n",
    "    if current_layer == 0:\n",
    "        net = tf.keras.layers.Conv2D(n_channels, kernel_size=[1, 3], activation=LeakyReLU,name='se_conv_%d' % current_layer,padding='SAME')(input)\n",
    "        net = norm_fn(name='se_norm_%d' % current_layer)(net)\n",
    "    else:\n",
    "        # The content of each intermediate layer is computed from the previous layer via a dilated convolution with 3 × 1 convolutional kernels\n",
    "        # “Here, we increase the dilation factor exponentially with depth from 2^0 for the 1st intermediate layer to 2^12 for the 13th one.” ([Germain et al., 2018, p. 2])\n",
    "        dilation_factor = 2 ** current_layer\n",
    "        net, pad_elements = signal_to_dilated(net, n_channels=n_channels, dilation=dilation_factor)\n",
    "        net = layers.Conv2D(n_channels, kernel_size=[1, 3], activation=LeakyReLU,name='se_conv_%d' % current_layer,padding='SAME')(net)\n",
    "        net = norm_fn(name='se_norm_%d' % current_layer)(net)\n",
    "        net = dilated_to_signal(net, n_channels=n_channels, pad_elements=pad_elements)\n",
    "net = layers.Conv2D(n_channels, kernel_size=[1, 3], activation=LeakyReLU, name='se_conv_last', padding='SAME')(net)\n",
    "net = norm_fn(name='se_norm_last')(net)\n",
    "net = layers.Conv2D(1, kernel_size=[1, 1], activation=None,\n",
    "                        name='se_fc_last', padding='SAME')(net)\n",
    "# undo the transpose and squeeze the feature dimension\n",
    "output = tf.squeeze(tf.transpose(net, [0, 2, 1, 3]), axis=-1)\n",
    "model = keras.Model(inputs=model_input, outputs=output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "data_path = os.path.join(os.getcwd(),'data')\n",
    "X = np.load(os.path.join(data_path, 'X_70_500_signal.npy'), allow_pickle=True)\n",
    "X = tf.ragged.stack([tf.constant(x) for x in X], axis=0)\n",
    "X = tf.expand_dims(X, axis=-1)\n",
    "\n",
    "Y = np.load(os.path.join(data_path, 'Y_70_500_signal.npy'), allow_pickle=True)\n",
    "Y = tf.ragged.stack([tf.constant(y) for y in Y], axis=0)\n",
    "Y = tf.expand_dims(Y, axis=-1)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "dataset = dataset.shuffle(seed=70, buffer_size=500)\n",
    "data_size = dataset.cardinality().numpy()\n",
    "train_size = int(0.7 * data_size)\n",
    "\n",
    "train_set = dataset.take(train_size)\n",
    "val_set = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nOOM when allocating tensor with shape[52001,32,128,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/se_conv_7/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13382]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMSE, optimizer\u001b[39m=\u001b[39moptimizer, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[39m# callbacks=[checkpoint, stop]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_set, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_set, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[checkpoint, stop],verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     19\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[52001,32,128,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/se_conv_7/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13382]"
     ]
    }
   ],
   "source": [
    "# A larger batch size can lead to faster training, but can also result in less accurate models. A smaller batch size can lead to slower training, but can also result in more accurate models.\n",
    "# start at 64/128\n",
    "# In general, you should start with a small number of epochs (e.g. 10-20) and increase the number of epochs until the model begins to overfit the training data. \n",
    "\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "SE_LOSS_LAYERS = 6 # NUMBER OF FEATURE LOSS LAYERS\n",
    "model_path = os.path.join(os.getcwd(),'saved','models', 'fcnn.model')\n",
    "if os.path.exists(model_path):\n",
    "    model.load_weights(model_path)\n",
    "checkpoint = callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,mode='min')\n",
    "stop = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(loss=tf.keras.losses.MSE, optimizer=optimizer, metrics=['mse'])\n",
    "# callbacks=[checkpoint, stop]\n",
    "history = model.fit(train_set, epochs=2, validation_data=val_set, batch_size=32,callbacks=[checkpoint, stop],verbose=1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "import os\n",
    "\n",
    "import sys, getopt\n",
    "\n",
    "# Variables\n",
    "SE_LAYERS = 13 # NUMBER OF INTERNAL LAYERS\n",
    "SE_CHANNELS = 64 # NUMBER OF FEATURE CHANNELS PER LAYER\n",
    "SE_LOSS_LAYERS = 6 # NUMBER OF FEATURE LOSS LAYERS\n",
    "SE_NORM = \"NM\" # TYPE OF LAYER NORMALIZATION (NM, SBN or None)\n",
    "SE_LOSS_TYPE = \"FL\" # TYPE OF TRAINING LOSS (L1, L2 or FL)\n",
    "\n",
    "# FEATURE LOSS NETWORK\n",
    "LOSS_LAYERS = 14 # NUMBER OF INTERNAL LAYERS\n",
    "LOSS_BASE_CHANNELS = 32 # NUMBER OF FEATURE CHANNELS PER LAYER IN FIRT LAYER\n",
    "LOSS_BLK_CHANNELS = 5 # NUMBER OF LAYERS BETWEEN CHANNEL NUMBER UPDATES\n",
    "LOSS_NORM = \"SBN\" # TYPE OF LAYER NORMALIZATION (NM, SBN or None)\n",
    "\n",
    "\n",
    "SET_WEIGHT_EPOCH = 10 # NUMBER OF EPOCHS BEFORE FEATURE LOSS BALANCE\n",
    "SAVE_EPOCHS = 10 # NUMBER OF EPOCHS BETWEEN MODEL SAVES\n",
    "\n",
    "log_file = open(\"logfile.txt\", 'w+')\n",
    "\n",
    "# COMMAND LINE OPTIONS\n",
    "model_path = os.path.join('saved','models', 'fcnn.model')\n",
    "loss_model_path = os.path.join('saved','models', 'floss.model')\n",
    "data_path = os.path.join('data')\n",
    "datafolder = \"dataset\"\n",
    "modfolder = \"models\"\n",
    "checkpoint = callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,mode='min')\n",
    "# try:\n",
    "#     opts, args = getopt.getopt(sys.argv[1:],\"hd:l:o:\",[\"ifolder=,lossfolder=,outfolder=\"])\n",
    "# except getopt.GetoptError:\n",
    "#     print('Usage: python senet_infer.py -d <datafolder> -l <lossfolder> -o <outfolder>')\n",
    "#     sys.exit(2)\n",
    "# for opt, arg in opts:\n",
    "#     if opt == '-h':\n",
    "#         print ('Usage: python senet_infer.py -d <datafolder> -l <lossfolder> -o <outfolder>')\n",
    "#         sys.exit()\n",
    "#     elif opt in (\"-d\", \"--datafolder\"):\n",
    "#         datafolder = arg\n",
    "#     elif opt in (\"-l\", \"--lossfolder\"):\n",
    "#         modfolder = arg\n",
    "#     elif opt in (\"-o\", \"--outfolder\"):\n",
    "#         outfolder = arg\n",
    "# print( 'Data folder is \"' + datafolder + '/\"')\n",
    "# print ('Loss model folder is \"' + modfolder + '/\"')\n",
    "# print( 'Output model folder is \"' + outfolder + '/\"')\n",
    "\n",
    "# SET LOSS FUNCTIONS AND PLACEHOLDERS\n",
    "with tf.name_scope('loss_weights'):\n",
    "    input_tensor = layers.Input(shape=(None, 1, None, 1), dtype=tf.float32)\n",
    "    clean_tensor = layers.Input(shape=(None, 1, None, 1), dtype=tf.float32)\n",
    "    # input=tf.placeholder(tf.float32,shape=[None,1,None,1])\n",
    "    # clean=tf.placeholder(tf.float32,shape=[None,1,None,1])\n",
    "        \n",
    "    enhanced_tensor=senet(input_tensor, n_layers=SE_LAYERS, norm_type=SE_NORM, n_channels=SE_CHANNELS)\n",
    "    # enhanced=senet(input, n_layers=SE_LAYERS, norm_type=SE_NORM, n_channels=SE_CHANNELS)\n",
    "        \n",
    "    if SE_LOSS_TYPE == \"L1\" or SE_LOSS_TYPE == \"L2\": # L1 LOSS\n",
    "        # loss_weights = tf.placeholder(tf.float32, shape=[])\n",
    "        loss_tensor = layers.Input(shape=None, dtype=tf.float32)\n",
    "        loss_fn = loss_function(clean_tensor, enhanced_tensor, type=SE_LOSS_TYPE)\n",
    "    else: # FEATURE LOSS\n",
    "        # loss_weights = tf.placeholder(tf.float32, shape=[SE_LOSS_LAYERS])\n",
    "        loss_tensor = layers.Input(shape=(SE_LOSS_LAYERS), dtype=tf.float32)\n",
    "        # loss_fn = featureloss(clean, enhanced, loss_weights, loss_layers=SE_LOSS_LAYERS, n_layers=LOSS_LAYERS, norm_type=LOSS_NORM,\n",
    "        #                          base_channels=LOSS_BASE_CHANNELS, blk_channels=LOSS_BLK_CHANNELS)\n",
    "        \n",
    "        loss_fn = featureloss(clean_tensor, enhanced_tensor, loss_tensor, loss_layers=SE_LOSS_LAYERS, n_layers=LOSS_LAYERS, norm_type=LOSS_NORM,\n",
    "                                 base_channels=LOSS_BASE_CHANNELS, blk_channels=LOSS_BLK_CHANNELS)\n",
    "\n",
    "# LOAD DATA\n",
    "trainset, valset = load_full_data_list(datafolder = datafolder)\n",
    "trainset, valset = load_full_data(trainset, valset)\n",
    "\n",
    "# TRAINING OPTIMIZER\n",
    "opt=tf.train.AdamOptimizer(learning_rate=1e-4).\\\n",
    "    minimize(loss_fn[0],var_list=[var for var in tf.trainable_variables() if var.name.startswith(\"se_\")])\n",
    "# As used in paper.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# BEGIN SCRIPT #########################################################################################################\n",
    "\n",
    "# INITIALIZE GPU CONFIG\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "print (\"Config ready\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print( \"Session initialized\")\n",
    "\n",
    "# LOAD FEATURE LOSS\n",
    "if SE_LOSS_TYPE == \"FL\":\n",
    "    loss_saver = tf.train.Saver([var for var in tf.trainable_variables() if var.name.startswith(\"loss_\")])\n",
    "    loss_saver.restore(sess, \"./%s/loss_model.ckpt\" % modfolder)\n",
    "    loss_train = np.zeros((len(trainset[\"innames\"]),SE_LOSS_LAYERS+1))\n",
    "    loss_val = np.zeros((len(valset[\"innames\"]),SE_LOSS_LAYERS+1))\n",
    "    loss_w = np.ones(SE_LOSS_LAYERS)\n",
    "else:\n",
    "    loss_train = np.zeros((len(trainset[\"innames\"]),1))\n",
    "    loss_val = np.zeros((len(valset[\"innames\"]),1))\n",
    "    loss_w = []\n",
    "    \n",
    "    \n",
    "saver = tf.train.Saver([var for var in tf.trainable_variables() if var.name.startswith(\"se_\")])\n",
    "Nepochs = 320\n",
    "#####################################################################################\n",
    "\n",
    "for epoch in range(1,Nepochs+1):\n",
    "    # TRAINING EPOCH ################################################################\n",
    "\n",
    "    ids = np.random.permutation(len(trainset[\"innames\"])) # RANDOM FILE ORDER\n",
    "\n",
    "    for id in tqdm(range(0, len(ids)), file=sys.stdout):\n",
    "\n",
    "        i = ids[id] # RANDOMIZED ITERATION INDEX\n",
    "        inputData = trainset[\"inaudio\"][i] # LOAD DEGRADED INPUT\n",
    "        outputData = trainset[\"outaudio\"][i] # LOAD GROUND TRUTH\n",
    "\n",
    "        # TRAINING ITERATION\n",
    "        _, loss_vec = sess.run([opt, loss_fn],\n",
    "                                feed_dict={input: inputData, clean: outputData, loss_weights: loss_w})\n",
    "\n",
    "        # SAVE ITERATION LOSS\n",
    "        loss_train[id,0] = loss_vec[0]\n",
    "        if SE_LOSS_TYPE == \"FL\":\n",
    "            for j in range(SE_LOSS_LAYERS):\n",
    "                loss_train[id,j+1] = loss_vec[j+1]\n",
    "\n",
    "    # PRINT EPOCH TRAINING LOSS AVERAGE\n",
    "    str = \"T: %d\\t \" % (epoch)\n",
    "    if SE_LOSS_TYPE == \"FL\":\n",
    "        for j in range(SE_LOSS_LAYERS+1):\n",
    "            str += \", %10.6e\"%(np.mean(loss_train, axis=0)[j])\n",
    "    else:\n",
    "        str += \", %10.6e\"%(np.mean(loss_train, axis=0)[0])\n",
    "\n",
    "    log_file.write(str + \"\\n\")\n",
    "    log_file.flush()\n",
    "\n",
    "    # SET WEIGHTS AFTER M EPOCHS\n",
    "    if SE_LOSS_TYPE == \"FL\" and epoch == SET_WEIGHT_EPOCH:\n",
    "        loss_w = np.mean(loss_train, axis=0)[1:]\n",
    "\n",
    "    # SAVE MODEL EVERY N EPOCHS\n",
    "    if epoch % SAVE_EPOCHS != 0:\n",
    "        continue\n",
    "\n",
    "    saver.save(sess, outfolder + \"/se_model.ckpt\")\n",
    "\n",
    "    # VALIDATION EPOCH ##############################################################\n",
    "\n",
    "    print(\"Validation epoch\")\n",
    "\n",
    "    for id in tqdm(range(0, len(valset[\"innames\"])), file=sys.stdout):\n",
    "\n",
    "        i = id # NON-RANDOMIZED ITERATION INDEX\n",
    "        inputData = valset[\"inaudio\"][i] # LOAD DEGRADED INPUT\n",
    "        outputData = valset[\"outaudio\"][i] # LOAD GROUND TRUTH\n",
    "\n",
    "        # VALIDATION ITERATION\n",
    "        output, loss_vec = sess.run([enhanced, loss_fn],\n",
    "                            feed_dict={input: inputData, clean: outputData, loss_weights: loss_w})\n",
    "\n",
    "        # SAVE ITERATION LOSS\n",
    "        loss_val[id,0] = loss_vec[0]\n",
    "        if SE_LOSS_TYPE == \"FL\":\n",
    "            for j in range(SE_LOSS_LAYERS):\n",
    "                loss_val[id,j+1] = loss_vec[j+1]\n",
    "\n",
    "    # PRINT VALIDATION EPOCH LOSS AVERAGE\n",
    "    str = \"V: %d \" % (epoch)\n",
    "    if SE_LOSS_TYPE == \"FL\":\n",
    "        for j in range(SE_LOSS_LAYERS+1):\n",
    "            str += \", %10.6e\"%(np.mean(loss_val, axis=0)[j]*1e9)\n",
    "    else:\n",
    "        str += \", %10.6e\"%(np.mean(loss_val, axis=0)[0]*1e9)\n",
    "\n",
    "    log_file.write(str + \"\\n\")\n",
    "    log_file.flush()\n",
    "\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
