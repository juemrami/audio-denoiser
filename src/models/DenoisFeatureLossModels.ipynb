{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be signal in signal out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras as keras\n",
    "\n",
    "\n",
    "\n",
    "# GENERATE DILATED LAYER FROM 1D SIGNAL\n",
    "def signal_to_dilated(signal, dilation, n_channels):\n",
    "    shape = tf.shape(signal)\n",
    "    pad_elements = dilation - 1 - (shape[2] + dilation - 1) % dilation\n",
    "    dilated = tf.pad(signal, [[0, 0], [0, 0], [0, pad_elements], [0, 0]])\n",
    "    dilated = tf.reshape(dilated, [shape[0],-1,dilation,n_channels])\n",
    "    return tf.transpose(dilated, perm=[0,2,1,3]), pad_elements\n",
    "\n",
    "\n",
    "# COLLAPSE DILATED LAYER TO 1D SIGNAL\n",
    "def dilated_to_signal(dilated, pad_elements, n_channels):\n",
    "    shape = tf.shape(dilated)\n",
    "    signal = tf.transpose(dilated, perm=[0,2,1,3])\n",
    "    signal = tf.reshape(signal, [shape[0],1,-1,n_channels])\n",
    "    return signal[:,:,:shape[1]*shape[2]-pad_elements,:]\n",
    "\n",
    "\n",
    "# IDENTITY INITIALIZATION OF CONV LAYERS\n",
    "def identity_initializer():\n",
    "    def _initializer(shape, dtype=tf.float32, partition_info=None):\n",
    "        array = np.zeros(shape, dtype=float)\n",
    "        cx, cy = shape[0]//2, shape[1]//2\n",
    "        for i in range(np.minimum(shape[2],shape[3])):\n",
    "            array[cx, cy, i, i] = 1\n",
    "        return tf.constant(array, dtype=dtype)\n",
    "    return _initializer\n",
    "\n",
    "\n",
    "# “In our experiments, simple training losses (e.g., L1) led to noticeably degraded output quality at lower signal-to-noise ratios (SNRs).” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=DZN467TR))\n",
    "def loss_function(target, current, type):\n",
    "    if type == 'L1':\n",
    "        return tf.reduce_mean(tf.abs(target-current))\n",
    "    elif type == 'L2':\n",
    "        return tf.reduce_mean(tf.square(target-current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“receptive field of the pipeline is 2^14 + 1 samples, i.e., about 1 s of audio for fs = 16 kHz.” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=WTGLQ8JQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-noising Network\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "class AdaptiveNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdaptiveNormalization, self).__init__(**kwargs)\n",
    "        self.alpha = tf.Variable(1.0, name='alpha')\n",
    "        self.beta = tf.Variable(0.0, name='beta')\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
    "    def call(self, x):\n",
    "        return self.alpha * x + self.beta * self.batch_norm(x)\n",
    "# “point-wise nonlinear leaky rectified linear unit (LReLU) [28] max(0.2x, x)” \n",
    "# ([Germain et al., 2018, p. 2]\n",
    "def LeakyReLU(x):\n",
    "    return tf.maximum(0.2*x,x)\n",
    "\n",
    "n_layers=7 # num of internal layers\n",
    "n_channels=16 # number of feature maps (64 in paper)\n",
    "norm_type=\"AN\"\n",
    "\n",
    "if norm_type == \"AN\": # Adaptive Norm\n",
    "    norm_fn = AdaptiveNormalization\n",
    "elif norm_type == \"SBN\": # Std Batch Norm\n",
    "    norm_fn = layers.BatchNormalization\n",
    "else: # NO LAYER NORMALIZATION\n",
    "    norm_fn = None\n",
    "model_input = tf.keras.layers.Input(shape=(None, 1), dtype=tf.float32) # input is a single channel waveform (time, 1)\n",
    "input = tf.expand_dims(model_input, axis=-1) # add a conv feature dimension (batch, time, 1, features)\n",
    "input = tf.transpose(input, [0, 2, 1, 3]) # transpose to (batch, 1, time, features)\n",
    "for current_layer in range(n_layers):\n",
    "    if current_layer == 0:\n",
    "        net = tf.keras.layers.Conv2D(n_channels, kernel_size=[1, 3], activation=LeakyReLU,name='se_conv_%d' % current_layer,padding='SAME')(input)\n",
    "        net = norm_fn(name='se_norm_%d' % current_layer)(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net) # I added this dropout layer\n",
    "    else:\n",
    "        # The content of each intermediate layer is computed from the previous layer via a dilated convolution with 3 × 1 convolutional kernels\n",
    "        # “Here, we increase the dilation factor exponentially with depth from 2^0 for the 1st intermediate layer to 2^12 for the 13th one.” ([Germain et al., 2018, p. 2])\n",
    "        dilation_factor = 2 ** current_layer\n",
    "        net, pad_elements = signal_to_dilated(net, n_channels=n_channels, dilation=dilation_factor)\n",
    "        net = layers.Conv2D(n_channels, kernel_size=[1, 3], activation=LeakyReLU,name='se_conv_%d' % current_layer,padding='SAME')(net)\n",
    "        net = norm_fn(name='se_norm_%d' % current_layer)(net)\n",
    "        net = dilated_to_signal(net, n_channels=n_channels, pad_elements=pad_elements)\n",
    "net = layers.Conv2D(n_channels, kernel_size=[1, 3], activation=LeakyReLU, name='se_conv_last', padding='SAME')(net)\n",
    "net = norm_fn(name='se_norm_last')(net)\n",
    "net = layers.Conv2D(1, kernel_size=[1, 1], activation='tanh',\n",
    "                        name='se_fc_last', padding='SAME')(net)\n",
    "# undo the transpose and squeeze the feature dimension\n",
    "output = tf.squeeze(tf.transpose(net, [0, 2, 1, 3]), axis=-1)\n",
    "model = keras.Model(inputs=model_input, outputs=output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['XLA_FLAGS'] = '--xla=false'\n",
    "import tensorflow as tf\n",
    "data_path = os.path.join(os.getcwd(),'data')\n",
    "X = np.load(os.path.join(data_path, 'inputs_70_500_signal.npy'), allow_pickle=True)\n",
    "X = tf.ragged.stack([tf.constant(x) for x in X], axis=0)\n",
    "X = tf.expand_dims(X, axis=-1)\n",
    "\n",
    "Y = np.load(os.path.join(data_path, 'targets_70_500_signal.npy'), allow_pickle=True)\n",
    "Y = tf.ragged.stack([tf.constant(y) for y in Y], axis=0)\n",
    "Y = tf.expand_dims(Y, axis=-1)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "dataset = dataset.shuffle(seed=70, buffer_size=500)\n",
    "data_size = dataset.cardinality().numpy()\n",
    "train_size = int(0.7 * data_size)\n",
    "\n",
    "train_set = dataset.take(train_size)\n",
    "val_set = dataset.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A larger batch size can lead to faster training, but can also result in less accurate models. A smaller batch size can lead to slower training, but can also result in more accurate models.\n",
    "# start at 64/128\n",
    "# In general, you should start with a small number of epochs (e.g. 10-20) and increase the number of epochs until the model begins to overfit the training data. \n",
    "tf.debugging.set_log_device_placement(True)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "from keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "SE_LOSS_LAYERS = 6 # NUMBER OF FEATURE LOSS LAYERS\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=['mse', 'mae', 'accuracy' ])\n",
    "model_path = os.path.join(os.getcwd(),'saved','models', 'fcnn_AN.model')\n",
    "if os.path.exists(model_path):\n",
    "    model.load_weights(model_path)\n",
    "    print('Model loaded from: ', model_path)\n",
    "checkpoint = callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,mode='min')\n",
    "stop = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "# callbacks=[checkpoint, stop]\n",
    "history = model.fit(train_set, epochs=25, validation_data=val_set, batch_size=128,callbacks=[checkpoint, stop],verbose=1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "idx = 100\n",
    "demo_tensor = X[idx]\n",
    "demo_target = Y[idx]\n",
    "model_input = tf.expand_dims(demo_tensor, axis=0)\n",
    "prediction = model.predict(model_input).squeeze()\n",
    "input = demo_tensor.numpy().squeeze()\n",
    "target = demo_target.numpy().squeeze()\n",
    "import soundfile as sf\n",
    "sf.write('input.wav', input, 16000)\n",
    "sf.write('prediction.wav', prediction, 16000)\n",
    "ipd.Audio(prediction, rate=16000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“To compute the loss between two waveforms, we apply a pretrained audio classification network to each waveform and compare the internal activation patterns induced in the network by the two signals” ([Germain et al., 2018, p. 1](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=1&annotation=Y3F49L4C))\n",
    "\n",
    "“The network consists of 15 convolutional layers with 3×1 kernels, batch normalization, LReLU units, and zero padding” ([Germain et al., 2018, p. 2](zotero://select/library/items/A6D78SNY)) ([pdf](zotero://open-pdf/library/items/P4HPP4P3?page=2&annotation=J3JNI54Q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE LOSS NETWORK\n",
    "import keras as keras\n",
    "\n",
    "n_layers=14\n",
    "training=True\n",
    "reuse=False\n",
    "norm_type=\"SBN\"\n",
    "# “The number of channels is doubled every 5 layers, with 32 channels in the first intermediate layer.” \n",
    "base_channels=32\n",
    "doubling_rate=5\n",
    "conv_layers = []\n",
    "if norm_type == \"NM\": # ADAPTIVE BATCH NORM\n",
    "    norm_fn = AdaptiveNormalization\n",
    "elif norm_type == \"SBN\": # BATCH NORM\n",
    "    norm_fn = layers.BatchNormalization\n",
    "else: # NO LAYER NORMALIZATION\n",
    "    norm_fn = None\n",
    "    \n",
    "for current_layer in range(n_layers):\n",
    "    n_channels = base_channels * (2 ** (current_layer // doubling_rate)) # UPDATE CHANNEL COUNT\n",
    "    if current_layer == 0:\n",
    "        # \"Each Layer is decimated by 2\" - just means stride of 2 in the time dimension.\n",
    "        net = layers.Conv2D(input, n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn, stride=[1, 2],\n",
    "                            scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "        conv_layers.append(net)\n",
    "    elif current_layer < n_layers - 1:\n",
    "        net = layers.Conv2D(conv_layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                            stride=[1, 2], scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "        conv_layers.append(net)\n",
    "    else:\n",
    "        net = layers.Conv2D(conv_layers[-1], n_channels, kernel_size=[1, 3], activation_fn=LeakyReLU, normalizer_fn=norm_fn,\n",
    "                            scope='loss_conv_%d' % current_layer, padding='SAME', reuse=reuse)\n",
    "        conv_layers.append(net)\n",
    "        # \"Each channel in the last layer is averaged-pooled to produce the output ferature vector.\"\n",
    "\n",
    "\n",
    "\n",
    "def featureloss(target, current, loss_weights, loss_layers, n_layers=14, norm_type=\"SBN\", base_channels=32, blk_channels=5):\n",
    "\n",
    "feat_current = LossNetwork(current, reuse=False, n_layers=n_layers, norm_type=norm_type)\n",
    "\n",
    "feat_target = LossNetwork(target, reuse=True, n_layers=n_layers, norm_type=norm_type,\n",
    "                        base_channels=base_channels, blk_channels=blk_channels)\n",
    "\n",
    "loss_vec = [0]\n",
    "#“The weights λm are set to balance the contribution of each layer to the loss. They are set to the inverse of the relative values of ‖Φm(ß) − Φm(g(x; θ))‖1 after 10 training epochs. (For these first 10 epochs, the weights are set to 1.)”\n",
    "for id in range(loss_layers):\n",
    "    loss_vec.append(loss_function(feat_current[id], feat_target[id], type=\"L1\") / loss_weights[id])\n",
    "# b) Denoising loss function:\n",
    "for id in range(1,loss_layers+1):\n",
    "    loss_vec[0] += loss_vec[id]\n",
    "\n",
    "return loss_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "import os\n",
    "\n",
    "import sys, getopt\n",
    "\n",
    "# Variables\n",
    "SE_LAYERS = 13 # NUMBER OF INTERNAL LAYERS\n",
    "SE_CHANNELS = 64 # NUMBER OF FEATURE CHANNELS PER LAYER\n",
    "SE_LOSS_LAYERS = 6 # NUMBER OF FEATURE LOSS LAYERS\n",
    "SE_NORM = \"NM\" # TYPE OF LAYER NORMALIZATION (NM, SBN or None)\n",
    "SE_LOSS_TYPE = \"FL\" # TYPE OF TRAINING LOSS (L1, L2 or FL)\n",
    "\n",
    "# FEATURE LOSS NETWORK\n",
    "LOSS_LAYERS = 14 # NUMBER OF INTERNAL LAYERS\n",
    "LOSS_BASE_CHANNELS = 32 # NUMBER OF FEATURE CHANNELS PER LAYER IN FIRT LAYER\n",
    "LOSS_BLK_CHANNELS = 5 # NUMBER OF LAYERS BETWEEN CHANNEL NUMBER UPDATES\n",
    "LOSS_NORM = \"SBN\" # TYPE OF LAYER NORMALIZATION (NM, SBN or None)\n",
    "\n",
    "\n",
    "SET_WEIGHT_EPOCH = 10 # NUMBER OF EPOCHS BEFORE FEATURE LOSS BALANCE\n",
    "SAVE_EPOCHS = 10 # NUMBER OF EPOCHS BETWEEN MODEL SAVES\n",
    "\n",
    "log_file = open(\"logfile.txt\", 'w+')\n",
    "\n",
    "# COMMAND LINE OPTIONS\n",
    "model_path = os.path.join('saved','models', 'fcnn.model')\n",
    "loss_model_path = os.path.join('saved','models', 'floss.model')\n",
    "data_path = os.path.join('data')\n",
    "datafolder = \"dataset\"\n",
    "modfolder = \"models\"\n",
    "checkpoint = callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,mode='min')\n",
    "# try:\n",
    "#     opts, args = getopt.getopt(sys.argv[1:],\"hd:l:o:\",[\"ifolder=,lossfolder=,outfolder=\"])\n",
    "# except getopt.GetoptError:\n",
    "#     print('Usage: python senet_infer.py -d <datafolder> -l <lossfolder> -o <outfolder>')\n",
    "#     sys.exit(2)\n",
    "# for opt, arg in opts:\n",
    "#     if opt == '-h':\n",
    "#         print ('Usage: python senet_infer.py -d <datafolder> -l <lossfolder> -o <outfolder>')\n",
    "#         sys.exit()\n",
    "#     elif opt in (\"-d\", \"--datafolder\"):\n",
    "#         datafolder = arg\n",
    "#     elif opt in (\"-l\", \"--lossfolder\"):\n",
    "#         modfolder = arg\n",
    "#     elif opt in (\"-o\", \"--outfolder\"):\n",
    "#         outfolder = arg\n",
    "# print( 'Data folder is \"' + datafolder + '/\"')\n",
    "# print ('Loss model folder is \"' + modfolder + '/\"')\n",
    "# print( 'Output model folder is \"' + outfolder + '/\"')\n",
    "\n",
    "# SET LOSS FUNCTIONS AND PLACEHOLDERS\n",
    "with tf.name_scope('loss_weights'):\n",
    "    input_tensor = layers.Input(shape=(None, 1, None, 1), dtype=tf.float32)\n",
    "    clean_tensor = layers.Input(shape=(None, 1, None, 1), dtype=tf.float32)\n",
    "    # input=tf.placeholder(tf.float32,shape=[None,1,None,1])\n",
    "    # clean=tf.placeholder(tf.float32,shape=[None,1,None,1])\n",
    "        \n",
    "    enhanced_tensor=senet(input_tensor, n_layers=SE_LAYERS, norm_type=SE_NORM, n_channels=SE_CHANNELS)\n",
    "    # enhanced=senet(input, n_layers=SE_LAYERS, norm_type=SE_NORM, n_channels=SE_CHANNELS)\n",
    "        \n",
    "    if SE_LOSS_TYPE == \"L1\" or SE_LOSS_TYPE == \"L2\": # L1 LOSS\n",
    "        # loss_weights = tf.placeholder(tf.float32, shape=[])\n",
    "        loss_tensor = layers.Input(shape=None, dtype=tf.float32)\n",
    "        loss_fn = loss_function(clean_tensor, enhanced_tensor, type=SE_LOSS_TYPE)\n",
    "    else: # FEATURE LOSS\n",
    "        # loss_weights = tf.placeholder(tf.float32, shape=[SE_LOSS_LAYERS])\n",
    "        loss_tensor = layers.Input(shape=(SE_LOSS_LAYERS), dtype=tf.float32)\n",
    "        # loss_fn = featureloss(clean, enhanced, loss_weights, loss_layers=SE_LOSS_LAYERS, n_layers=LOSS_LAYERS, norm_type=LOSS_NORM,\n",
    "        #                          base_channels=LOSS_BASE_CHANNELS, blk_channels=LOSS_BLK_CHANNELS)\n",
    "        \n",
    "        loss_fn = featureloss(clean_tensor, enhanced_tensor, loss_tensor, loss_layers=SE_LOSS_LAYERS, n_layers=LOSS_LAYERS, norm_type=LOSS_NORM,\n",
    "                                 base_channels=LOSS_BASE_CHANNELS, blk_channels=LOSS_BLK_CHANNELS)\n",
    "\n",
    "# LOAD DATA\n",
    "trainset, valset = load_full_data_list(datafolder = datafolder)\n",
    "trainset, valset = load_full_data(trainset, valset)\n",
    "\n",
    "# TRAINING OPTIMIZER\n",
    "opt=tf.train.AdamOptimizer(learning_rate=1e-4).\\\n",
    "    minimize(loss_fn[0],var_list=[var for var in tf.trainable_variables() if var.name.startswith(\"se_\")])\n",
    "# As used in paper.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# BEGIN SCRIPT #########################################################################################################\n",
    "\n",
    "# INITIALIZE GPU CONFIG\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "print (\"Config ready\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print( \"Session initialized\")\n",
    "\n",
    "# LOAD FEATURE LOSS\n",
    "if SE_LOSS_TYPE == \"FL\":\n",
    "    loss_saver = tf.train.Saver([var for var in tf.trainable_variables() if var.name.startswith(\"loss_\")])\n",
    "    loss_saver.restore(sess, \"./%s/loss_model.ckpt\" % modfolder)\n",
    "    loss_train = np.zeros((len(trainset[\"innames\"]),SE_LOSS_LAYERS+1))\n",
    "    loss_val = np.zeros((len(valset[\"innames\"]),SE_LOSS_LAYERS+1))\n",
    "    loss_w = np.ones(SE_LOSS_LAYERS)\n",
    "else:\n",
    "    loss_train = np.zeros((len(trainset[\"innames\"]),1))\n",
    "    loss_val = np.zeros((len(valset[\"innames\"]),1))\n",
    "    loss_w = []\n",
    "    \n",
    "    \n",
    "saver = tf.train.Saver([var for var in tf.trainable_variables() if var.name.startswith(\"se_\")])\n",
    "Nepochs = 320\n",
    "#####################################################################################\n",
    "\n",
    "for epoch in range(1,Nepochs+1):\n",
    "    # TRAINING EPOCH ################################################################\n",
    "\n",
    "    ids = np.random.permutation(len(trainset[\"innames\"])) # RANDOM FILE ORDER\n",
    "\n",
    "    for id in tqdm(range(0, len(ids)), file=sys.stdout):\n",
    "\n",
    "        i = ids[id] # RANDOMIZED ITERATION INDEX\n",
    "        inputData = trainset[\"inaudio\"][i] # LOAD DEGRADED INPUT\n",
    "        outputData = trainset[\"outaudio\"][i] # LOAD GROUND TRUTH\n",
    "\n",
    "        # TRAINING ITERATION\n",
    "        _, loss_vec = sess.run([opt, loss_fn],\n",
    "                                feed_dict={input: inputData, clean: outputData, loss_weights: loss_w})\n",
    "\n",
    "        # SAVE ITERATION LOSS\n",
    "        loss_train[id,0] = loss_vec[0]\n",
    "        if SE_LOSS_TYPE == \"FL\":\n",
    "            for j in range(SE_LOSS_LAYERS):\n",
    "                loss_train[id,j+1] = loss_vec[j+1]\n",
    "\n",
    "    # PRINT EPOCH TRAINING LOSS AVERAGE\n",
    "    str = \"T: %d\\t \" % (epoch)\n",
    "    if SE_LOSS_TYPE == \"FL\":\n",
    "        for j in range(SE_LOSS_LAYERS+1):\n",
    "            str += \", %10.6e\"%(np.mean(loss_train, axis=0)[j])\n",
    "    else:\n",
    "        str += \", %10.6e\"%(np.mean(loss_train, axis=0)[0])\n",
    "\n",
    "    log_file.write(str + \"\\n\")\n",
    "    log_file.flush()\n",
    "\n",
    "    # SET WEIGHTS AFTER M EPOCHS\n",
    "    if SE_LOSS_TYPE == \"FL\" and epoch == SET_WEIGHT_EPOCH:\n",
    "        loss_w = np.mean(loss_train, axis=0)[1:]\n",
    "\n",
    "    # SAVE MODEL EVERY N EPOCHS\n",
    "    if epoch % SAVE_EPOCHS != 0:\n",
    "        continue\n",
    "\n",
    "    saver.save(sess, outfolder + \"/se_model.ckpt\")\n",
    "\n",
    "    # VALIDATION EPOCH ##############################################################\n",
    "\n",
    "    print(\"Validation epoch\")\n",
    "\n",
    "    for id in tqdm(range(0, len(valset[\"innames\"])), file=sys.stdout):\n",
    "\n",
    "        i = id # NON-RANDOMIZED ITERATION INDEX\n",
    "        inputData = valset[\"inaudio\"][i] # LOAD DEGRADED INPUT\n",
    "        outputData = valset[\"outaudio\"][i] # LOAD GROUND TRUTH\n",
    "\n",
    "        # VALIDATION ITERATION\n",
    "        output, loss_vec = sess.run([enhanced, loss_fn],\n",
    "                            feed_dict={input: inputData, clean: outputData, loss_weights: loss_w})\n",
    "\n",
    "        # SAVE ITERATION LOSS\n",
    "        loss_val[id,0] = loss_vec[0]\n",
    "        if SE_LOSS_TYPE == \"FL\":\n",
    "            for j in range(SE_LOSS_LAYERS):\n",
    "                loss_val[id,j+1] = loss_vec[j+1]\n",
    "\n",
    "    # PRINT VALIDATION EPOCH LOSS AVERAGE\n",
    "    str = \"V: %d \" % (epoch)\n",
    "    if SE_LOSS_TYPE == \"FL\":\n",
    "        for j in range(SE_LOSS_LAYERS+1):\n",
    "            str += \", %10.6e\"%(np.mean(loss_val, axis=0)[j]*1e9)\n",
    "    else:\n",
    "        str += \", %10.6e\"%(np.mean(loss_val, axis=0)[0]*1e9)\n",
    "\n",
    "    log_file.write(str + \"\\n\")\n",
    "    log_file.flush()\n",
    "\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
